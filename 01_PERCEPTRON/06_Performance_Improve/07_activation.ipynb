{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90550345",
   "metadata": {},
   "source": [
    "## vanishing gradient decent---\n",
    " A. **activation function**--An activation function transforms the weighted sum of inputs into the output of a neuron, helping the network capture non-linear relationships.\n",
    "\n",
    "✅ Hidden Layers:\n",
    "ReLU (Rectified Linear Unit) – Most common and effective for CNNs and deep networks.\n",
    "f(x) = max(0, x)\n",
    "<br>\n",
    "Variants:\n",
    "<br>\n",
    "Leaky ReLU – Helps prevent dead neurons.\n",
    "<br>\n",
    "ELU/SELU – Sometimes used for self-normalizing networks.\n",
    "\n",
    "✅ Output Layer:\n",
    "Binary Classification (2 classes):\n",
    "<br>\n",
    "Use Sigmoid activation.\n",
    "Output: probability between 0 and 1.\n",
    "\n",
    "Multiclass Classification (3+ classes, one class per input):\n",
    "<br>\n",
    "Use Softmax activation.<br>\n",
    "✅Output: probability distribution across classes.\n",
    "\n",
    "Regression:\n",
    "<br>\n",
    "Use Linear activation (i.e., no activation).\n",
    "<br>\n",
    "If you're working on your potato disease detection project:\n",
    "<br>\n",
    "✅Hidden layers → use ReLU\n",
    "<br>\n",
    "Output layer:\n",
    "<br>\n",
    "Use Softmax if you're classifying between multiple diseases.\n",
    "<br>\n",
    "Use Sigmoid if you're doing binary classification (e.g. healthy vs diseased).\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b221302",
   "metadata": {},
   "source": [
    " B. **weight initilization**\n",
    " <br>\n",
    "***Things not to do***---\n",
    "1. Zero initilization\n",
    "2. non-zero constant initilization\n",
    "3. random init. with small weights\n",
    "4. random init. with big weights\n",
    "\n",
    "***----What should we do***\n",
    "---Random initilization--\n",
    "1. Xavier/glorat init(tenh,sigmoid)=(1/n) where n is the number of inpute weights in node\n",
    "2. He init(relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b365daee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(10,activation='relu',input_dim=2),kernal_initilization='he_normal')\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
